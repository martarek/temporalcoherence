\subsection{Hyper-parameters}
\subsubsection{Description}
The hyper-parameters used in the baseline CNN and his temporal coherence counterpart are presented in table~\ref{tab:hyperparams}.

\begin{table}[h]
\center
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
Hyper-parameters       & Descritption                                                                                                                     \\ \midrule
LR1                    & The learning rate associated with the standard CNN backpropagation stage.                                                        \\
LR2                    & The learning rate associated the backpropagation for two consecutives entries and for the one with two non-consecutives entries. \\
DC                     & The Decreasing constant of the learning rate. \\
Sizes                  & The sizes of the 4 different layers of the neural network.                                                                       \\
Seed                   & The seed of the random number generator. \\
Look-ahead Steps (LAS) & The amount of steps during training that the system will do after the condition                                                  \\
Look-ahead Delay (LAD) & Number of steps before the look-ahead is enabled.                                                                                \\
Mini-batch Size        & The size of the minibatch.                                                                                                       \\
margin                 & $\delta$ is defined at~\ref{eq:delta}.                                                                                         \\ \bottomrule
\end{tabular}
\caption{Description of hyper-parameters.}
\label{tab:hyperparams}
\end{table}

Some values were fixed for simplicity and are shown at table~\ref{tab:hyperparamsvals}. As displayed in this table, LR2 and $\delta$ are not applicable for the baseline CNN but are used for temporal coherence CNN (TC-CNN).


\begin{table}[ht]
\label{tab:hyperparamsvals}
\begin{center}
\begin{tabular}{lll}

Hyper-parameters & CNN & TC-CNN \\ 
\midrule
LR2 & N/A & Variable \\ 

LAS & 5 & 10 \\ 

LAD & 0 & 7 \\ 

$\delta$ & N/A & 1 \\
\bottomrule
\end{tabular} 
\caption{Predefined values of hyper-parameters.}
\end{center}
\end{table}

\subsubsection{Selection}
The exploration of the hyper-parameters was done iteratively. At the beginning, they were randomly attributed within a manually created set. Based on the success of specific sets, another subset was manually generated using the most promising hyper-parameters and using variations around those hyper-parameters thus converging toward a better solution. This procedure was repeated until an acceptable performance was attained. This procedure would benefit from more standardized methods.  
